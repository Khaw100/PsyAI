{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd33c54-2703-4572-865e-8a3bb1c0bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15306ba1-e1c5-47d0-805f-0c44eeccafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyA_JFNhIlr5R0jFowohE0K2SBqc84HV0R4\"\n",
    "AIzaSyDCeFx_uDoTs3VWLULoitWJjb9UmyTqFjw\n",
    "os.environ['GEMINI_API_KEY'] = os.getenv('GEMINI_API_KEY', API_KEY)\n",
    "# Define the model\n",
    "gemini_model = 'gemini-2.5-flash'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ca2aa-9541-48b8-a7e9-280dd9955148",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710eb87e-26b0-43b4-aa46-548388434148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='QrWvaI6AJNCMmtkP09j1iA4', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Imagine a really smart parrot that can learn to repeat things and even understand what they mean, eventually even creating new \"sentences\" based on what it\\'s learned.  That\\'s kind of how AI works.\\n\\nAI is a computer program that learns from data.  We give it tons of examples (like showing the parrot lots of pictures and words), and it finds patterns and relationships in that data.  Then, when we give it new information, it uses what it learned to make predictions', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1756345667, model='gemini-1.5-flash', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=14, total_tokens=114, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['GEMINI_API_KEY'],\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    ")\n",
    "# Make a chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain how AI works in simple terms.\"}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "# Print the response\n",
    "# print(response.choices[0].message['content'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a25f74-6955-47e6-b6f8-545dae9efd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a really smart parrot that can learn to repeat things and even understand what they mean, eventually even creating new \"sentences\" based on what it's learned.  That's kind of how AI works.\n",
      "\n",
      "AI is a computer program that learns from data.  We give it tons of examples (like showing the parrot lots of pictures and words), and it finds patterns and relationships in that data.  Then, when we give it new information, it uses what it learned to make predictions\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56443108-37e9-4905-99d9-ba6a82b9cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "941bea3b-3db3-4099-8cf7-38cf9fefc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9676d13-4a22-448a-9743-08e2ac865a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base\\\\anxiety\\\\anxiety.txt', 'doc_type': 'anxiety'}, page_content='Example sentences for Anxiety:\\n- I constantly worry about everything.\\n- My heart races when I think about work.\\n- I feel nervous even in safe situations.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\child_psychology\\\\child_psychology.txt', 'doc_type': 'child_psychology'}, page_content='Example sentences for Child Psychology:\\n- My child has trouble making friends.\\n- They often seem anxious and withdrawn.\\n- Their behavior has changed dramatically recently.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\depression\\\\depression.txt', 'doc_type': 'depression'}, page_content='Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\relationship_issues\\\\relationship_issues.txt', 'doc_type': 'relationship_issues'}, page_content='Example sentences for Relationship Issues:\\n- We argue almost every day.\\n- I feel emotionally distant from my partner.\\n- Communication between us is breaking down.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\stress\\\\stress.txt', 'doc_type': 'stress'}, page_content=\"Example sentences for Stress:\\n- I feel overwhelmed by my responsibilities.\\n- I can't relax even when I have free time.\\n- My mind is always racing with thoughts.\\n\"),\n",
       " Document(metadata={'source': 'knowledge-base\\\\trauma\\\\trauma.txt', 'doc_type': 'trauma'}, page_content='Example sentences for Trauma:\\n- I have flashbacks of a painful event.\\n- Loud noises make me feel unsafe.\\n- I avoid places that remind me of the past.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\work_burnout\\\\work_burnout.txt', 'doc_type': 'work_burnout'}, page_content='Example sentences for Work Burnout:\\n- I dread going to work each morning.\\n- I feel exhausted no matter how much I rest.\\n- My job used to excite me, now it drains me.\\n')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c1dfb1a-ba25-45e7-86bd-a44ba20cfe44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30843b89-f3e8-4f7f-9901-c6889ce928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8df71c01-50ac-4cee-9fae-8728c524f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35ca11a1-4a2e-45a1-a2be-ec4daef42dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "vectorstore.save_local(\"mental_health_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0b5b216-d489-4ac5-aab9-50c0b510c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, k=3):\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    return \"\\n\".join([doc.page_content for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a75c6b7e-6706-4773-aa51-7d78c7c6afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I feel emotionally numb and can't get out of bed\"\n",
    "# query = \"I feel hopeless and don't want to live anymore\"\n",
    "context = retrieve_context(query)\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# User input: \"{query}\"\n",
    "\n",
    "# Relevant context:\n",
    "# {context}\n",
    "\n",
    "# Classify the emotional state and detect suicidal ideation. Respond in JSON:\n",
    "# {{ \"category\": \"...\", \"suicidal_ideation\": \"Yes/No\" }}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    Classify the following user input.\n",
    "\n",
    "    1. Identify the main problem category (choose from: depression, anxiety, stress, trauma, relationship, work burnout, child psychology, other).\n",
    "    2. Detect if suicidal ideation is present (Yes/No).\n",
    "    3. Output in strict JSON format: \n",
    "    {{\n",
    "      \"category\": \"...\",\n",
    "      \"suicidal_ideation\": \"Yes/No\"\n",
    "    }}\n",
    "\n",
    "    User input: \"{query}\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "df388894-5bf2-4982-bc88-f1541a65aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Classify the following user input.\n",
      "\n",
      "    1. Identify the main problem category (choose from: depression, anxiety, stress, trauma, relationship, work burnout, child psychology, other).\n",
      "    2. Detect if suicidal ideation is present (Yes/No).\n",
      "    3. Output in strict JSON format: \n",
      "    {\n",
      "      \"category\": \"...\",\n",
      "      \"suicidal_ideation\": \"Yes/No\"\n",
      "    }\n",
      "\n",
      "    User input: \"I feel emotionally numb and can't get out of bed\"\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0261d094-83af-4f2a-ae75-32f8a71e59f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"category\": \"depression\",\n",
      "  \"suicidal_ideation\": \"No\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a psychological screening assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=150 \n",
    "    )\n",
    "\n",
    "output_text = response.choices[0].message.content\n",
    "cleaned_output = output_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0bfae2be-0fda-4bc4-90a9-d189cf3d2182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"category\": \"depression\",\\n  \"suicidal_ideation\": \"No\"\\n}\\n```\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b86b5c4e-2abb-497d-a246-9a7c1ca915d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"category\": \"depression\",\n",
      "  \"suicidal_ideation\": \"No\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85a5e002-bbe0-4082-8fcd-d2d4e798cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'depression', 'suicidal_ideation': 'No'}\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(cleaned_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b1f6dbe-28cb-449a-acd3-95af4254bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "psychologists = [\n",
    "    {\"name\": \"Dr. Andini Putri, M.Psi., Psikolog\", \"expertise\": [\"depression\", \"anxiety\"], \"location\": \"Jakarta\", \"contact\": \"andini@example.com\"},\n",
    "    {\"name\": \"Dr. Bima Santoso, M.Psi., Psikolog\", \"expertise\": [\"stress\", \"work burnout\"], \"location\": \"Bandung\", \"contact\": \"bima@example.com\"},\n",
    "    {\"name\": \"Dr. Clara Wijaya, M.Psi., Psikolog\", \"expertise\": [\"relationship\", \"marriage counseling\"], \"location\": \"Surabaya\", \"contact\": \"clara@example.com\"},\n",
    "    {\"name\": \"Dr. Daniel Pratama, M.Psi., Psikolog\", \"expertise\": [\"trauma\", \"PTSD\"], \"location\": \"Yogyakarta\", \"contact\": \"daniel@example.com\"},\n",
    "    {\"name\": \"Dr. Eka Lestari, M.Psi., Psikolog\", \"expertise\": [\"child psychology\", \"learning difficulties\"], \"location\": \"Jakarta\", \"contact\": \"eka@example.com\"}\n",
    "]\n",
    "\n",
    "def recommend_psychologist(category, psychologists):\n",
    "    for psy in psychologists:\n",
    "        if category.lower() in [exp.lower() for exp in psy[\"expertise\"]]:\n",
    "            return psy\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7be89015-6f61-4d70-9ea1-6ddd2778bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "rec = recommend_psychologist(classification[\"category\"], psychologists)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2cdd8bb3-db5b-4f14-aba5-281e5da96718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='osuvaOXZI6Kdz7IPyMfXkQM', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1756351394, model='gemini-2.5-flash', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=0, prompt_tokens=185, total_tokens=334, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8829a39-851d-4774-aad9-e8d24858a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7db40b31-f7a7-4656-9c6a-920b0e4535c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'other', 'suicidal_ideation': 'No'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('GEMINI_API_KEY', API_KEY),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    ")\n",
    "\n",
    "def classify_user_input(user_text):\n",
    "\n",
    "    # define prompt\n",
    "    prompt = f\"\"\"\n",
    "    Classify the following user input.\n",
    "\n",
    "    1. Identify the main problem category (choose from: depression, anxiety, stress, trauma, relationship, work burnout, child psychology, other).\n",
    "    2. Detect if suicidal ideation is present (Yes/No).\n",
    "    3. Output in strict JSON format: \n",
    "    {{\n",
    "      \"category\": \"...\",\n",
    "      \"suicidal_ideation\": \"Yes/No\"\n",
    "    }}\n",
    "\n",
    "    User input: \"{user_text}\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a psychological screening assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=150 \n",
    "    )\n",
    "\n",
    "    output_text = response.choices[0].message.content\n",
    "    try:\n",
    "        return json.loads(output_text)\n",
    "    except:\n",
    "        return {\"category\": \"other\", \"suicidal_ideation\": \"No\"}\n",
    "\n",
    "psychologists = [\n",
    "    {\"name\": \"Dr. Andini Putri, M.Psi., Psikolog\", \"expertise\": [\"depression\", \"anxiety\"], \"location\": \"Jakarta\", \"contact\": \"andini@example.com\"},\n",
    "    {\"name\": \"Dr. Bima Santoso, M.Psi., Psikolog\", \"expertise\": [\"stress\", \"work burnout\"], \"location\": \"Bandung\", \"contact\": \"bima@example.com\"},\n",
    "    {\"name\": \"Dr. Clara Wijaya, M.Psi., Psikolog\", \"expertise\": [\"relationship\", \"marriage counseling\"], \"location\": \"Surabaya\", \"contact\": \"clara@example.com\"},\n",
    "    {\"name\": \"Dr. Daniel Pratama, M.Psi., Psikolog\", \"expertise\": [\"trauma\", \"PTSD\"], \"location\": \"Yogyakarta\", \"contact\": \"daniel@example.com\"},\n",
    "    {\"name\": \"Dr. Eka Lestari, M.Psi., Psikolog\", \"expertise\": [\"child psychology\", \"learning difficulties\"], \"location\": \"Jakarta\", \"contact\": \"eka@example.com\"}\n",
    "]\n",
    "\n",
    "def recommend_psychologist(category, psychologists):\n",
    "    for psy in psychologists:\n",
    "        if category.lower() in [exp.lower() for exp in psy[\"expertise\"]]:\n",
    "            return psy\n",
    "    return None\n",
    "# Test\n",
    "\n",
    "user_story = \"I feel hopeless and don't want to live anymore.\"\n",
    "classification = classify_user_input(user_story)\n",
    "print(classification)\n",
    "rec = recommend_psychologist(classification[\"category\"], psychologists)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2b2d5d8-ff55-43be-9e8b-06b22eb948bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"category\": \"depression\",\n",
      "  \"suicidal_ideation\": \"No\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4b7403a-cd83-432d-aa5c-3b704dc939c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "json.loads(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2dfa53-7ccc-49d5-a192-b6068eb89b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dabd744b-588e-4308-9bbc-fe3531bfe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    folders = glob.glob(f\"{folder}/*\")\n",
    "    text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "    \n",
    "    documents = []\n",
    "    for folder in folders:\n",
    "        doc_type = os.path.basename(folder)\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "        folder_docs = loader.load()\n",
    "        for doc in folder_docs:\n",
    "            doc.metadata[\"doc_type\"] = doc_type\n",
    "            documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bc3672da-ba74-430f-a540-38d8d53ee78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(documents : list, embedding_model):\n",
    "    # Chunking documents\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "    vectorstore.save_local(\"mental_health_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f453ef79-6efd-4cae-9b00-308b70269699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, k=3):\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    return \"\\n\".join([doc.page_content for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9a240-d719-4674-a36c-ff3914c72412",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "    Classify the following user input.\n",
    "\n",
    "    1. Identify the main problem category (choose from: depression, anxiety, stress, trauma, relationship, work burnout, child psychology, other).\n",
    "    2. Detect if suicidal ideation is present (Yes/No).\n",
    "    3. Output in strict JSON format: \n",
    "    {{\n",
    "      \"category\": \"...\",\n",
    "      \"suicidal_ideation\": \"Yes/No\"\n",
    "    }}\n",
    "\n",
    "    User input: \"{query}\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "986fc74e-9580-42cb-85d6-a1eb23aebeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_user_input(prompt):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a psychological screening assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=150 \n",
    "    )\n",
    "\n",
    "    output_text = response.choices[0].message.content\n",
    "    cleaned_output = output_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    try:\n",
    "        return json.loads(output_text)\n",
    "    except:\n",
    "        return {\"category\": \"other\", \"suicidal_ideation\": \"No\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a217dd6-b570-4fd8-b7e1-4b4db98d9e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66241f-9a9e-468c-ae66-d3b7f9da88fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6417a3d-8ed5-435a-8232-4e696edc2411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b496491-1c2b-4b58-bc54-2e8a177d203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26623f-2a34-4704-bbb5-b9e248a460ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab063f-8a66-4984-ba82-724fa1b23c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aaea23-5e05-4453-8d64-e259df76f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b86fa35-870c-4209-b29a-661ea1ed3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = load_data(\"knowledge-base\")\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee72a09-0339-4a7b-980f-6106d1d46c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9add4954-649d-48b7-a124-cd852a8e7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base\\\\anxiety\\\\anxiety.txt', 'doc_type': 'anxiety'}, page_content='Example sentences for Anxiety:\\n- I constantly worry about everything.\\n- My heart races when I think about work.\\n- I feel nervous even in safe situations.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\child_psychology\\\\child_psychology.txt', 'doc_type': 'child_psychology'}, page_content='Example sentences for Child Psychology:\\n- My child has trouble making friends.\\n- They often seem anxious and withdrawn.\\n- Their behavior has changed dramatically recently.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\depression\\\\depression.txt', 'doc_type': 'depression'}, page_content='Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\relationship_issues\\\\relationship_issues.txt', 'doc_type': 'relationship_issues'}, page_content='Example sentences for Relationship Issues:\\n- We argue almost every day.\\n- I feel emotionally distant from my partner.\\n- Communication between us is breaking down.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\stress\\\\stress.txt', 'doc_type': 'stress'}, page_content=\"Example sentences for Stress:\\n- I feel overwhelmed by my responsibilities.\\n- I can't relax even when I have free time.\\n- My mind is always racing with thoughts.\\n\"),\n",
       " Document(metadata={'source': 'knowledge-base\\\\trauma\\\\trauma.txt', 'doc_type': 'trauma'}, page_content='Example sentences for Trauma:\\n- I have flashbacks of a painful event.\\n- Loud noises make me feel unsafe.\\n- I avoid places that remind me of the past.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\work_burnout\\\\work_burnout.txt', 'doc_type': 'work_burnout'}, page_content='Example sentences for Work Burnout:\\n- I dread going to work each morning.\\n- I feel exhausted no matter how much I rest.\\n- My job used to excite me, now it drains me.\\n')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab486f25-f17a-4acc-890e-b7f8bad5a246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adb9f5-7dac-4b26-85f8-221c98ab28f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd1d8ad4-16ae-4e03-a0f9-599b21acfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_action(self, user_text):\n",
    "    self.prompt = f\"\"\"\n",
    "    You are an AI psychological triage agent with tool access.\n",
    "    Decide action based on user input.\n",
    "\n",
    "    Available actions:\n",
    "    - \"search_db\": if user input matches a psychological category.\n",
    "    - \"escalate\": if user mentions suicidal thoughts.\n",
    "    - \"education\": if user seems confused or asks for help understanding.\n",
    "    - \"clarify\": if user input is vague or ambiguous.\n",
    "\n",
    "    Respond STRICT JSON:\n",
    "    {{\n",
    "      \"action\": \"...\",\n",
    "      \"query\": \"...\"   # keyword or issue\n",
    "    }}\n",
    "\n",
    "    User input: \"{user_text}\"\n",
    "    \"\"\"\n",
    "    self.response = self.llm.chat.completions.create(\n",
    "        model=self.model,\n",
    "        messages=[{\"role\": \"user\", \"content\": self.prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return {\"action\": \"clarify\", \"query\": \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6273e-227c-46ad-88c5-d9523f2f2aab",
   "metadata": {},
   "source": [
    "## Multi Agent (Hopefully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3573698f-26fa-4e08-ad3e-9f3dc761d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('GEMINI_API_KEY', API_KEY),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1fac2e1-e5fa-4916-a23b-995bf913b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    def __init__(self, llm_client, tools,model):\n",
    "        self.llm = llm_client\n",
    "        self.tools = tools\n",
    "        self.agents = {\n",
    "            \"classify\": ClassificationAgent(llm_client, tools,model),\n",
    "            \"clarify\": ClarificationAgent(llm_client, model),\n",
    "            \"educate\": EducationAgent(tools)\n",
    "        }\n",
    "        self.model = model\n",
    "\n",
    "    def run(self, user_text):\n",
    "        # Step 1: Klasifikasi awal\n",
    "        classification = self.agents[\"classify\"].run(user_text)\n",
    "        category = classification[\"category\"]\n",
    "        suicidal = classification.get(\"suicidal_ideation\", \"No\")\n",
    "        context_chunks = classification.get(\"context\", [])\n",
    "    \n",
    "        if category != \"other\":\n",
    "            thought = \"Category identified. Proceeding with recommendation and education.\"\n",
    "            recommended = self.tools[\"match_psychologist\"](category)\n",
    "            education = self.agents[\"educate\"].run(category)\n",
    "    \n",
    "            result = {\n",
    "                \"category\": category,\n",
    "                \"context\": context_chunks,\n",
    "                \"recommendations\": recommended,\n",
    "                \"education\": education[\"education\"],\n",
    "                \"clarified\": False,\n",
    "                \"suicidal_ideation\": suicidal\n",
    "            }\n",
    "    \n",
    "        else:\n",
    "            clarification = self.agents[\"clarify\"].run(user_text)\n",
    "            clarified_text = clarification[\"follow_up\"]\n",
    "            reclassification = self.agents[\"classify\"].run(clarified_text)\n",
    "            new_category = reclassification[\"category\"]\n",
    "            suicidal = reclassification.get(\"suicidal_ideation\", \"No\")\n",
    "            context_chunks = reclassification.get(\"context\", [])\n",
    "    \n",
    "            if new_category != \"other\":\n",
    "                thought = \"Clarified input classified. Proceeding with recommendation and education.\"\n",
    "                recommended = self.tools[\"match_psychologist\"](new_category)\n",
    "                education = self.agents[\"educate\"].run(new_category)\n",
    "    \n",
    "                result = {\n",
    "                    \"category\": new_category,\n",
    "                    \"context\": context_chunks,\n",
    "                    \"recommendations\": recommended,\n",
    "                    \"education\": education[\"education\"],\n",
    "                    \"clarified\": True,\n",
    "                    \"suicidal_ideation\": suicidal,\n",
    "                    \"clarified_text\": clarified_text\n",
    "                }\n",
    "    \n",
    "            else:\n",
    "                thought = \"Still unclear after clarification. Providing general education.\"\n",
    "                education = self.agents[\"educate\"].run(\"mental health basics\")\n",
    "    \n",
    "                result = {\n",
    "                    \"category\": \"other\",\n",
    "                    \"context\": [],\n",
    "                    \"recommendations\": [],\n",
    "                    \"education\": education[\"education\"],\n",
    "                    \"clarified\": True,\n",
    "                    \"suicidal_ideation\": suicidal,\n",
    "                    \"clarified_text\": clarified_text\n",
    "                }\n",
    "    \n",
    "        return {\n",
    "            \"thought\": thought,\n",
    "            \"result\": result\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0519f003-1f8c-40a0-bcaf-ce0f92d38ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EducationAgent:\n",
    "    def __init__(self, tools):\n",
    "        self.retrieve_context = tools[\"retrieve_context\"]\n",
    "\n",
    "    def run(self, category):\n",
    "        context_chunks = self.retrieve_context(category, purpose=\"education\")\n",
    "        if not context_chunks:\n",
    "            return {\"education\": f\"Maaf, belum ada informasi edukatif untuk kategori '{category}'.\"}\n",
    "        education_text = \"\\n\".join(context_chunks)\n",
    "        return {\"education\": education_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c1b2de-714f-4918-be1e-4478fbb87b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class ClarificationAgent:\n",
    "    def __init__(self, llm_client, model):\n",
    "        self.llm = llm_client\n",
    "        self.model = model\n",
    "        self.prompt = None\n",
    "\n",
    "    def run(self, user_text):\n",
    "        self.prompt = f\"\"\"\n",
    "        You are a clarification agent in a psychological triage system.\n",
    "        The user's input may be vague, ambiguous, or lacking detail.\n",
    "\n",
    "        Your job is to ask a gentle, specific follow-up question to clarify their concern.\n",
    "        Do not classify or diagnose—just ask a question that helps the user express themselves more clearly.\n",
    "\n",
    "        User input: \"{user_text}\"\n",
    "\n",
    "        Respond in JSON:\n",
    "        {{\n",
    "          \"thought\": \"Why clarification is needed\",\n",
    "          \"follow_up\": \"Your clarifying question\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.llm.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": self.prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            output_text = response.choices[0].message.content\n",
    "            cleaned = output_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            return json.loads(cleaned)\n",
    "        except:\n",
    "            return {\n",
    "                \"thought\": \"Failed to parse response. Defaulting to generic clarification.\",\n",
    "                \"follow_up\": \"Boleh ceritakan lebih detail tentang apa yang kamu rasakan akhir-akhir ini?\"\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "567206e3-1f0c-4fbb-a089-5fd7d386d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationAgent:\n",
    "    def __init__(self, llm_client, tools, model):\n",
    "        self.llm = llm_client\n",
    "        self.tools = tools\n",
    "        self.model = model\n",
    "        self.prompt = None\n",
    "\n",
    "    def run(self, user_text):\n",
    "        context_chunks = self.tools[\"retrieve_context\"](user_text, purpose=\"classification\")\n",
    "        context = \"\\n\".join(context_chunks)\n",
    "\n",
    "        self.prompt = f\"\"\"\n",
    "        You are a psychological classification agent.\n",
    "        \n",
    "        Your task is to classify the user's emotional state based **only** on the provided context below.\n",
    "        If the user's input does not clearly match any of the examples or descriptions in the context, return:\n",
    "        {{ \"category\": \"other\", \"suicidal_ideation\": \"No\" }}\n",
    "        \n",
    "        Do not guess or infer categories outside the context. Only use categories explicitly present in the context.\n",
    "        \n",
    "        User input:\n",
    "        \"{user_text}\"\n",
    "        \n",
    "        Relevant context:\n",
    "        {context}\n",
    "        \n",
    "        Respond in JSON format:\n",
    "        {{\n",
    "          \"category\": \"...\",  // must match one of the categories in context or be \"other\"\n",
    "          \"suicidal_ideation\": \"Yes\" or \"No\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        response = self.llm.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": self.prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            output_text = response.choices[0].message.content\n",
    "            cleaned = output_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            return json.loads(cleaned)\n",
    "        except:\n",
    "            return {\"category\": \"other\", \"suicidal_ideation\": \"No\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "891e578a-0b03-4ce6-a049-562096d74640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class VectorPipeline:\n",
    "    def __init__(self, data_folder=\"knowledge-base\", index_path=\"mental_health_index\"):\n",
    "        self.data_folder = data_folder\n",
    "        self.index_path = index_path\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = None\n",
    "        self.documents = None\n",
    "\n",
    "    def load_data(self):\n",
    "        folders = glob.glob(f\"{self.data_folder}/*\")\n",
    "        text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "        documents = []\n",
    "    \n",
    "        for folder in folders:\n",
    "            doc_type = os.path.basename(folder)\n",
    "            loader = DirectoryLoader(folder, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "            folder_docs = loader.load()\n",
    "    \n",
    "            for doc in folder_docs:\n",
    "                filename = os.path.basename(doc.metadata[\"source\"])\n",
    "                if \"sample\" in filename or \"example\" in filename:\n",
    "                    doc.metadata[\"purpose\"] = \"classification\"\n",
    "                elif \"info\" in filename or \"explanation\" in filename:\n",
    "                    doc.metadata[\"purpose\"] = \"education\"\n",
    "                else:\n",
    "                    doc.metadata[\"purpose\"] = \"general\"\n",
    "    \n",
    "                doc.metadata[\"doc_type\"] = doc_type\n",
    "                documents.append(doc)\n",
    "    \n",
    "        print(f\"Loaded {len(documents)} documents\")\n",
    "        return documents\n",
    "\n",
    "\n",
    "    def create_or_update_index(self):\n",
    "        self.documents = self.load_data()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "        split_docs = splitter.split_documents(self.documents)\n",
    "        print(f\"Number of split docs: {len(split_docs)}\")\n",
    "\n",
    "        if os.path.exists(self.index_path):\n",
    "            print(\"🔄 Updating existing index...\")\n",
    "            self.vectorstore = FAISS.load_local(self.index_path, self.embedding_model, allow_dangerous_deserialization = True)\n",
    "            self.vectorstore.add_documents(split_docs)\n",
    "        else:\n",
    "            print(\"🆕 Creating new index...\")\n",
    "            self.vectorstore = FAISS.from_documents(split_docs, self.embedding_model)\n",
    "\n",
    "        self.vectorstore.save_local(self.index_path)\n",
    "\n",
    "    def load_index(self):\n",
    "        if not os.path.exists(self.index_path):\n",
    "            raise FileNotFoundError(f\"Index not found at {self.index_path}\")\n",
    "        self.vectorstore = FAISS.load_local(self.index_path, self.embedding_model, allow_dangerous_deserialization = True)\n",
    "\n",
    "    def retrieve_context(self, query: str, k: int = 3, purpose: str = None):\n",
    "        if not self.vectorstore:\n",
    "            self.load_index()\n",
    "        results = self.vectorstore.similarity_search(query, k=k)\n",
    "        if purpose:\n",
    "            results = [doc for doc in results if doc.metadata.get(\"purpose\") == purpose]\n",
    "        return [doc.page_content for doc in results]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e69ff3b-2b5a-426d-b07b-9b022d57a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents\n",
      "Number of split docs: 7\n",
      "🔄 Updating existing index...\n",
      "['Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.', 'Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.', 'Example sentences for Anxiety:\\n- I constantly worry about everything\\n- My heart races when I think about work']\n"
     ]
    }
   ],
   "source": [
    "vp = VectorPipeline(data_folder=\"knowledge-base\")\n",
    "vp.create_or_update_index()\n",
    "\n",
    "# Retrieve context\n",
    "chunks = vp.retrieve_context(\"I feel hopeless and don't want to live anymore.\")\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13006b6c-ca5c-46b9-ac93-73f12cff5289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI: 1.102.0\n",
      "LangChain: 0.3.27\n",
      "FAISS: 1.12.0\n",
      "Sentence-Transformers: 5.1.0\n"
     ]
    }
   ],
   "source": [
    "import openai, langchain, faiss, sentence_transformers\n",
    "\n",
    "print(\"OpenAI:\", openai.__version__)\n",
    "print(\"LangChain:\", langchain.__version__)\n",
    "print(\"FAISS:\", faiss.__version__)\n",
    "print(\"Sentence-Transformers:\", sentence_transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af164257-059d-40b6-ae2e-2d86e10e87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base\\\\anxiety\\\\anxiety.txt', 'doc_type': 'anxiety'}, page_content='Example sentences for Anxiety:\\n- I constantly worry about everything\\n- My heart races when I think about work'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\child_psychology\\\\child_psychology.txt', 'doc_type': 'child_psychology'}, page_content='Example sentences for Child Psychology:\\n- My child has trouble making friends.\\n- They often seem anxious and withdrawn.\\n- Their behavior has changed dramatically recently\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\depression\\\\depression.txt', 'doc_type': 'depression'}, page_content='Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\relationship_issues\\\\relationship_issues.txt', 'doc_type': 'relationship_issues'}, page_content='Example sentences for Relationship Issues:\\n- We argue almost every day.\\n- I feel emotionally distant from my partner. \\n- Communication between us is breaking down.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\stress\\\\stress.txt', 'doc_type': 'stress'}, page_content=\"Example sentences for Stress:\\n- I feel overwhelmed by my responsibilities.\\n- I can't relax even when I have free time.\\n- My mind is always racing with thoughts.\"),\n",
       " Document(metadata={'source': 'knowledge-base\\\\trauma\\\\trauma.txt', 'doc_type': 'trauma'}, page_content='Example sentences for Trauma:\\n- I have flashbacks of a painful event.\\n- Loud noises make me feel unsafe.\\n- I avoid places that remind me of the past.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\work_burnout\\\\work_burnout.txt', 'doc_type': 'work_burnout'}, page_content='Example sentences for Work Burnout.\\n- I dread going to work each morning.\\n- I feel exhausted no matter how much I rest.\\n- My job use to excite me, now it drains me.\\n')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0bd502-f282-43de-bc13-bacc82b63bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class PsychologistMatcher:\n",
    "    def __init__(self, filepath=\"psychologist_data.json\"):\n",
    "        self.filepath = filepath\n",
    "        self.psychologists = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def match_by_category(self, category):\n",
    "        category = category.lower()\n",
    "        return [\n",
    "            p for p in self.psychologists\n",
    "            if category in [e.lower() for e in p.get(\"expertise\", [])]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d9058a7-4d4e-4f81-aaad-e039a2d69936",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PsychologistMatcher()\n",
    "dt = a.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93f9b5fb-d1ed-4e10-8ac5-b56d8e0a9c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Dr. Andini Prasetyo',\n",
       "  'expertise': ['anxiety', 'depression'],\n",
       "  'location': 'Jakarta',\n",
       "  'contact': 'andini@mentalcare.id'},\n",
       " {'name': 'Dr. Raka Santosa',\n",
       "  'expertise': ['trauma', 'grief'],\n",
       "  'location': 'Bandung',\n",
       "  'contact': 'raka@healingcenter.id'},\n",
       " {'name': 'Dr. Sinta Wijaya',\n",
       "  'expertise': ['self-esteem', 'relationship'],\n",
       "  'location': 'Surabaya',\n",
       "  'contact': 'sinta@mindspace.id'},\n",
       " {'name': 'Dr. Yoga Mahendra',\n",
       "  'expertise': ['depression', 'suicidal ideation'],\n",
       "  'location': 'Yogyakarta',\n",
       "  'contact': 'yoga@lifeline.id'},\n",
       " {'name': 'Dr. Nia Ramadhani',\n",
       "  'expertise': ['anxiety', 'panic disorder'],\n",
       "  'location': 'Jakarta',\n",
       "  'contact': 'nia@calmclinic.id'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a3bbcc17-88ca-4be9-8cf8-685a2a887678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"mental_health_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10ccddf-020c-4f23-9b83-a1c4fa727b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class ToolInitializer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_folder=\"knowledge-base\",\n",
    "        index_path=\"mental_health_index\",\n",
    "        psychologist_file=\"psikolog_data.json\"\n",
    "        ):\n",
    "        self.vector_pipeline = VectorPipeline(\n",
    "            data_folder=data_folder,\n",
    "            index_path=index_path\n",
    "        )\n",
    "        self.matcher = PsychologistMatcher(filepath=psychologist_file)\n",
    "\n",
    "    def setup(self, create_index_if_missing=True):\n",
    "        if os.path.exists(self.vector_pipeline.index_path):\n",
    "            self.vector_pipeline.load_index()\n",
    "        elif create_index_if_missing:\n",
    "            self.vector_pipeline.create_or_update_index()\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Index not found and create_index_if_missing=False\")\n",
    "\n",
    "        return {\n",
    "            \"retrieve_context\": self.vector_pipeline.retrieve_context,\n",
    "            \"match_psychologist\": self.matcher.match_by_category\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bbaab6a-e219-402a-8eb0-415421ac51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi tool\n",
    "tool_initializer = ToolInitializer()\n",
    "tools = tool_initializer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52680c80-109a-4f71-bfd6-c478fbfe279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retrieve_context': <bound method VectorPipeline.retrieve_context of <__main__.VectorPipeline object at 0x0000019A1F3E00A0>>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6779e0c9-77fb-4fcb-b3e9-8bb5f41dc465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Depression', 'suicidal_ideation': 'No'}\n"
     ]
    }
   ],
   "source": [
    "agent = ClassifyAgent(llm_client=client, tools=tools)\n",
    "result = agent.run(\"Saya merasa sangat tertekan dan tidak punya harapan\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb4729d0-53e0-46f1-bace-d5b12b1c2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are a psychological classification agent.\n",
      "\n",
      "        User input:\n",
      "        \"Saya merasa sangat tertekan dan tidak punya harapan\"\n",
      "\n",
      "        Relevant context:\n",
      "        Example sentences for Depression:\n",
      "- I feel hopeless and empty.\n",
      "- Nothing brings me joy anymore.\n",
      "- I struggle to get out of bed every day.\n",
      "Example sentences for Depression:\n",
      "- I feel hopeless and empty.\n",
      "- Nothing brings me joy anymore.\n",
      "- I struggle to get out of bed every day.\n",
      "Example sentences for Depression:\n",
      "- I feel hopeless and empty.\n",
      "- Nothing brings me joy anymore.\n",
      "- I struggle to get out of bed every day.\n",
      "\n",
      "        Classify the emotional state and detect suicidal ideation. Respond in JSON:\n",
      "        {\n",
      "            \"category\": \"...\",\n",
      "            \"suicidal_ideation\": \"Yes/No\"\n",
      "        }\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(agent.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe1673c3-3a18-4014-9f47-fa4d097099c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator(client, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c79e7351-f4b8-469e-9eb9-5f18dbb9e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Saya tidak tahu apa yang saya rasakan. Mungkin sedih, mungkin lelah, atau entah apa.\"\n",
    "temp = orchestrator.run(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33db6906-133c-4220-b848-e7ffe166fbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Thought: \n",
      "🎯 Action: {'action': 'search_db', 'query': 'Unspecified emotional distress'}\n",
      "📦 Result: search_db\n"
     ]
    }
   ],
   "source": [
    "print(\"🧠 Thought:\", temp[\"thought\"])\n",
    "print(\"🎯 Action:\", temp[\"action\"])\n",
    "print(\"📦 Result:\", temp[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1278b0a-75a7-4cf1-82a4-bc8133d347ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are an AI psychological triage agent with tool access.\n",
      "        Decide action based on user input.\n",
      "\n",
      "        Available actions:\n",
      "        - \"search_db\": if user input matches a psychological category.\n",
      "        - \"escalate\": if user mentions suicidal thoughts.\n",
      "        - \"education\": if user seems confused or asks for help understanding.\n",
      "        - \"clarify\": if user input is vague or ambiguous.\n",
      "\n",
      "        Respond STRICT JSON:\n",
      "        {\n",
      "          \"action\": \"...\",\n",
      "          \"query\": \"...\"   # keyword or issue\n",
      "        }\n",
      "\n",
      "        User input: \"Saya tidak tahu apa yang saya rasakan. Mungkin sedih, mungkin lelah, atau entah apa.\"\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(orchestrator.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de451d18-2883-4ba5-98f9-5b79aed58d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': '',\n",
       " 'action': {'action': 'search_db', 'query': 'Unspecified emotional distress'},\n",
       " 'result': 'search_db'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e5c4e2-5165-47c1-bbef-161cc8c13539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are an AI psychological triage agent with tool access.\n",
      "        Decide action based on user input.\n",
      "\n",
      "        Available actions:\n",
      "        - \"search_db\": if user input matches a psychological category.\n",
      "        - \"escalate\": if user mentions suicidal thoughts.\n",
      "        - \"education\": if user seems confused or asks for help understanding.\n",
      "        - \"clarify\": if user input is vague or ambiguous.\n",
      "\n",
      "        Respond STRICT JSON:\n",
      "        {\n",
      "          \"action\": \"...\",\n",
      "          \"query\": \"...\"   # keyword or issue\n",
      "        }\n",
      "\n",
      "        User input: \"Saya tidak tahu apa yang saya rasakan. Mungkin sedih, mungkin lelah, atau entah apa.\"\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(orchestrator.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b7c699-cd5d-4195-9caa-f8018c407ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"action\": \"clarify\",\n",
      "  \"query\": \"Unspecified feelings of sadness and fatigue\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(orchestrator.response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c29e1af-2c9d-471d-bf83-5b4bd1a6a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self):\n",
    "    folders = glob.glob(f\"{self.data_folder}/*\")\n",
    "    text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "    documents = []\n",
    "\n",
    "    for folder in folders:\n",
    "        doc_type = os.path.basename(folder)\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "        folder_docs = loader.load()\n",
    "\n",
    "        for doc in folder_docs:\n",
    "            filename = os.path.basename(doc.metadata[\"source\"])\n",
    "            if \"sample\" in filename or \"example\" in filename:\n",
    "                doc.metadata[\"purpose\"] = \"classification\"\n",
    "            elif \"info\" in filename or \"explanation\" in filename:\n",
    "                doc.metadata[\"purpose\"] = \"education\"\n",
    "            else:\n",
    "                doc.metadata[\"purpose\"] = \"general\"\n",
    "\n",
    "            doc.metadata[\"doc_type\"] = doc_type\n",
    "            documents.append(doc)\n",
    "\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e0bd2ef-f91c-4368-a825-0f4cd67daf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'knowledge-base\\\\anxiety\\\\anxiety_examples.txt', 'purpose': 'classification', 'doc_type': 'anxiety'}, page_content='Example sentences for Anxiety:\\n- I constantly worry about everything\\n- My heart races when I think about work'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\anxiety\\\\anxiety_information.txt', 'purpose': 'education', 'doc_type': 'anxiety'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\child_psychology\\\\child_psychology_examples.txt', 'purpose': 'classification', 'doc_type': 'child_psychology'}, page_content='Example sentences for Child Psychology:\\n- My child has trouble making friends.\\n- They often seem anxious and withdrawn.\\n- Their behavior has changed dramatically recently\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\child_psychology\\\\child_psychology_information.txt', 'purpose': 'education', 'doc_type': 'child_psychology'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\depression\\\\depression_examples.txt', 'purpose': 'classification', 'doc_type': 'depression'}, page_content='Example sentences for Depression:\\n- I feel hopeless and empty.\\n- Nothing brings me joy anymore.\\n- I struggle to get out of bed every day.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\depression\\\\depression_information.txt', 'purpose': 'education', 'doc_type': 'depression'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\relationship_issues\\\\relationship_issues_examples.txt', 'purpose': 'classification', 'doc_type': 'relationship_issues'}, page_content='Example sentences for Relationship Issues:\\n- We argue almost every day.\\n- I feel emotionally distant from my partner. \\n- Communication between us is breaking down.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\relationship_issues\\\\relationship_issues_information.txt', 'purpose': 'education', 'doc_type': 'relationship_issues'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\stress\\\\stress_examples.txt', 'purpose': 'classification', 'doc_type': 'stress'}, page_content=\"Example sentences for Stress:\\n- I feel overwhelmed by my responsibilities.\\n- I can't relax even when I have free time.\\n- My mind is always racing with thoughts.\"),\n",
       " Document(metadata={'source': 'knowledge-base\\\\stress\\\\stress_information.txt', 'purpose': 'education', 'doc_type': 'stress'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\trauma\\\\trauma_examples.txt', 'purpose': 'classification', 'doc_type': 'trauma'}, page_content='Example sentences for Trauma:\\n- I have flashbacks of a painful event.\\n- Loud noises make me feel unsafe.\\n- I avoid places that remind me of the past.'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\trauma\\\\trauma_information.txt', 'purpose': 'education', 'doc_type': 'trauma'}, page_content=''),\n",
       " Document(metadata={'source': 'knowledge-base\\\\work_burnout\\\\work_burnout_examples.txt', 'purpose': 'classification', 'doc_type': 'work_burnout'}, page_content='Example sentences for Work Burnout.\\n- I dread going to work each morning.\\n- I feel exhausted no matter how much I rest.\\n- My job use to excite me, now it drains me.\\n'),\n",
       " Document(metadata={'source': 'knowledge-base\\\\work_burnout\\\\work_burnout_information.txt', 'purpose': 'education', 'doc_type': 'work_burnout'}, page_content='')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_data()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab1bbac0-8416-4003-b336-dab4e7677934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "model = \"vllm-qwen3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27025380-1362-4cf3-98c1-f7eefdee5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi tool pipeline\n",
    "tool_initializer = ToolInitializer(\n",
    "    data_folder=\"knowledge-base\",\n",
    "    index_path=\"mental_health_index\",\n",
    "    psychologist_file=\"psychologist_data.json\"\n",
    ")\n",
    "tools = tool_initializer.setup(create_index_if_missing=True)\n",
    "\n",
    "# Inisialisasi Orchestrator\n",
    "orchestrator = Orchestrator(client, tools, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8acf09b5-e7ce-4f0b-bd41-d318564d554a",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Authentication Error - Expired Key. Key Expiry time 2025-08-30 01:12:10.669000+00:00 and current time 2025-08-30 12:26:13.805335+00:00', 'type': 'expired_key', 'param': '7bb8c028918b5d3b967e28c46f6d7d1191408bd4728244fa8f27b65d1d23690c', 'code': '400'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaya bingung\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43morchestrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[49], line 14\u001b[0m, in \u001b[0;36mOrchestrator.run\u001b[1;34m(self, user_text)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_text):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Step 1: Klasifikasi awal\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassify\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     category \u001b[38;5;241m=\u001b[39m classification[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     16\u001b[0m     suicidal \u001b[38;5;241m=\u001b[39m classification\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuicidal_ideation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 35\u001b[0m, in \u001b[0;36mClassificationAgent.run\u001b[1;34m(self, user_text)\u001b[0m\n\u001b[0;32m     10\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(context_chunks)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124mYou are a psychological classification agent.\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[0;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1146\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Authentication Error - Expired Key. Key Expiry time 2025-08-30 01:12:10.669000+00:00 and current time 2025-08-30 12:26:13.805335+00:00', 'type': 'expired_key', 'param': '7bb8c028918b5d3b967e28c46f6d7d1191408bd4728244fa8f27b65d1d23690c', 'code': '400'}}"
     ]
    }
   ],
   "source": [
    "user_input = \"Saya bingung\"\n",
    "output = orchestrator.run(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7654f1c2-ff17-4ce2-bf92-439e82d9e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'category': 'other',\n",
      "            'clarified': True,\n",
      "            'clarified_text': 'Could you tell me a little more about what is '\n",
      "                              'making you feel confused?',\n",
      "            'context': [],\n",
      "            'education': 'Maaf, belum ada informasi edukatif untuk kategori '\n",
      "                         \"'mental health basics'.\",\n",
      "            'recommendations': [],\n",
      "            'suicidal_ideation': 'No'},\n",
      " 'thought': 'Still unclear after clarification. Providing general education.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f38a7-e8ab-47e5-8f6c-419d26bb6f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef541b62-95bf-4998-a2fc-a6b8f0c137c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {\"awaiting_clarification\": False, \"follow_up\": None}\n",
    "\n",
    "def chatbot_response(user_input, history):\n",
    "    if session_state[\"awaiting_clarification\"]:\n",
    "        # User menjawab pertanyaan klarifikasi\n",
    "        clarified_input = user_input\n",
    "        session_state[\"awaiting_clarification\"] = False\n",
    "        session_state[\"follow_up\"] = None\n",
    "\n",
    "        result = orchestrator.run(clarified_input)[\"result\"]\n",
    "        return format_response(result)\n",
    "\n",
    "    else:\n",
    "        # Input awal\n",
    "        output = orchestrator.run(user_input)\n",
    "        result = output[\"result\"]\n",
    "\n",
    "        if result[\"clarified\"]:\n",
    "            clarification = orchestrator.agents[\"clarify\"].run(user_input)\n",
    "            follow_up = clarification[\"follow_up\"]\n",
    "            session_state[\"awaiting_clarification\"] = True\n",
    "            session_state[\"follow_up\"] = follow_up\n",
    "            return f\"🤔 Terima kasih sudah berbagi. Boleh aku tanya sedikit lebih spesifik?\\n{follow_up}\"\n",
    "\n",
    "        return format_response(result)\n",
    "\n",
    "def format_response(result):\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "\n",
    "    response = f\"🧠 Kategori: {category}\\n\\n📘 Edukasi:\\n{education}\\n\\n👥 Rekomendasi Psikolog:\\n\"\n",
    "    for i, p in enumerate(recommendations, 1):\n",
    "        response += (\n",
    "            f\"{i}. {p['name']} ({p['location']})\\n\"\n",
    "            f\"   ✉️ {p['contact']}\\n\"\n",
    "            f\"   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "        )\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f760da12-ea9b-47f2-a322-54023f17a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chatbot_response).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4d956-43f0-4c24-893d-78b2ab03327b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a882a571-83c0-4ecf-a358-ea094ff80893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\queueing.py\", line 667, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\route_utils.py\", line 349, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\blocks.py\", line 2274, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\blocks.py\", line 1779, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\chat_interface.py\", line 551, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\chat_interface.py\", line 925, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Lesty\\AppData\\Local\\Temp\\ipykernel_10784\\2304467039.py\", line 31, in chatbot_response\n",
      "    output = orchestrator.run(user_input)\n",
      "  File \"C:\\Users\\Lesty\\AppData\\Local\\Temp\\ipykernel_10784\\2821950804.py\", line 34, in run\n",
      "    clarification = self.agents[\"clarify\"].run(user_text)\n",
      "  File \"C:\\Users\\Lesty\\AppData\\Local\\Temp\\ipykernel_10784\\775966387.py\", line 26, in run\n",
      "    response = self.llm.chat.completions.create(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1147, in create\n",
      "    return self._post(\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-flash'}, 'quotaValue': '50'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# State untuk melacak apakah sedang menunggu jawaban klarifikasi\n",
    "session_state = {\"awaiting_clarification\": False, \"follow_up\": None}\n",
    "\n",
    "def format_response(result):\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "\n",
    "    response = f\"🧠 Kategori: {category}\\n\\n📘 Edukasi:\\n{education}\\n\\n👥 Rekomendasi Psikolog:\\n\"\n",
    "    for i, p in enumerate(recommendations, 1):\n",
    "        response += (\n",
    "            f\"{i}. {p['name']} ({p['location']})\\n\"\n",
    "            f\"   ✉️ {p['contact']}\\n\"\n",
    "            f\"   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "        )\n",
    "    return response.strip()\n",
    "\n",
    "def chatbot_response(user_input, history):\n",
    "    if session_state[\"awaiting_clarification\"]:\n",
    "        # User menjawab pertanyaan klarifikasi\n",
    "        clarified_input = user_input\n",
    "        session_state[\"awaiting_clarification\"] = False\n",
    "        session_state[\"follow_up\"] = None\n",
    "\n",
    "        result = orchestrator.run(clarified_input)[\"result\"]\n",
    "        return format_response(result)\n",
    "\n",
    "    else:\n",
    "        output = orchestrator.run(user_input)\n",
    "        result = output[\"result\"]\n",
    "\n",
    "        if result[\"clarified\"]:\n",
    "            clarification = orchestrator.agents[\"clarify\"].run(user_input)\n",
    "            follow_up = clarification[\"follow_up\"]\n",
    "            session_state[\"awaiting_clarification\"] = True\n",
    "            session_state[\"follow_up\"] = follow_up\n",
    "            return f\"🤔 Terima kasih sudah berbagi. Boleh aku tanya sedikit lebih spesifik?\\n{follow_up}\"\n",
    "\n",
    "        return format_response(result)\n",
    "\n",
    "gr.ChatInterface(fn=chatbot_response).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b096d28-c3f8-442f-98bb-debc4620140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input):\n",
    "    result = orchestrator.run(user_input)[\"result\"]\n",
    "\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "    clarified = result[\"clarified\"]\n",
    "    suicidal = result[\"suicidal_ideation\"]\n",
    "\n",
    "    # Header respons\n",
    "    response = f\"🧠 Hai, terima kasih sudah berbagi.\\n\\n\"\n",
    "\n",
    "    if clarified:\n",
    "        response += \"Kami telah mengklarifikasi input kamu agar lebih jelas.\\n\\n\"\n",
    "\n",
    "    response += f\"**Kategori yang terdeteksi:** {category}\\n\"\n",
    "    response += f\"**Indikasi pikiran menyakiti diri sendiri:** {suicidal}\\n\\n\"\n",
    "\n",
    "    # Edukasi\n",
    "    response += f\"📘 **Penjelasan singkat tentang '{category}':**\\n{education}\\n\\n\"\n",
    "\n",
    "    # Rekomendasi psikolog\n",
    "    if recommendations:\n",
    "        response += \"👥 **Psikolog yang direkomendasikan:**\\n\"\n",
    "        for i, p in enumerate(recommendations, 1):\n",
    "            response += (\n",
    "                f\"{i}. {p['name']} ({p['location']})\\n\"\n",
    "                f\"   ✉️ {p['contact']}\\n\"\n",
    "                f\"   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        response += \"⚠️ Maaf, belum ada rekomendasi psikolog untuk kategori ini.\\n\"\n",
    "\n",
    "    # Penutup\n",
    "    response += \"\\n🙏 Kamu tidak sendiri. Jika kamu merasa butuh bantuan lebih lanjut, silakan hubungi psikolog yang tersedia atau lanjutkan percakapan ini.\"\n",
    "\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40c890a9-9e6c-45bf-9e32-73b0c658c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=chatbot_response, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20e32a44-7c74-4c09-bf3e-a1d38cb273bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lesty\\Documents\\Portofolio\\PsyAI\\psyai\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot_response(user_input, history):\n",
    "    result = orchestrator.run(user_input)[\"result\"]\n",
    "\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "\n",
    "    response = f\"🧠 Kategori: {category}\\n\\n📘 Edukasi:\\n{education}\\n\\n👥 Rekomendasi Psikolog:\\n\"\n",
    "    for i, p in enumerate(recommendations, 1):\n",
    "        response += (\n",
    "            f\"{i}. {p['name']} ({p['location']})\\n\"\n",
    "            f\"   ✉️ {p['contact']}\\n\"\n",
    "            f\"   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "        )\n",
    "\n",
    "    return response\n",
    "gr.ChatInterface(fn=chatbot_response).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14d21e8a-dbca-4008-a7ef-5189837908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input):\n",
    "    result = orchestrator.run(user_input)[\"result\"]\n",
    "\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "\n",
    "    response = f\"\"\"\n",
    "🧠 **Kategori yang terdeteksi:** {category}\n",
    "\n",
    "📘 **Penjelasan singkat:**\n",
    "{education}\n",
    "\n",
    "👥 **Psikolog yang direkomendasikan:**\n",
    "\"\"\"\n",
    "\n",
    "    for i, p in enumerate(recommendations, 1):\n",
    "        response += f\"\\n{i}. {p['name']} ({p['location']})\\n   ✉️ {p['contact']}\\n   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "\n",
    "    response += \"\\n🙏 Jika kamu merasa butuh bantuan lebih lanjut, jangan ragu untuk menghubungi salah satu psikolog di atas.\"\n",
    "\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c094646-1d27-43f3-900a-76e2f63dff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=chatbot_response, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c4b9a-586f-4cbb-857b-e9bdf4829d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6f56bad-b39e-4951-a1d0-86e41f8f2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradioNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading gradio-5.44.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (4.10.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.12.1 (from gradio)\n",
      "  Downloading gradio_client-1.12.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (2.2.6)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (25.0)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.12.11-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.47.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from gradio-client==1.12.1->gradio) (2025.7.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.12.1->gradio)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lesty\\documents\\portofolio\\psyai\\psyai\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
      "Downloading gradio-5.44.1-py3-none-any.whl (60.2 MB)\n",
      "   ---------------------------------------- 0.0/60.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 4.2/60.2 MB 22.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 9.4/60.2 MB 24.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 15.2/60.2 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 20.7/60.2 MB 25.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 26.0/60.2 MB 25.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 31.5/60.2 MB 25.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 36.7/60.2 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 41.9/60.2 MB 25.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 47.7/60.2 MB 25.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 53.2/60.2 MB 25.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 58.5/60.2 MB 25.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 60.2/60.2 MB 24.3 MB/s  0:00:02\n",
      "Downloading gradio_client-1.12.1-py3-none-any.whl (324 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.3 MB 27.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.3 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 24.5 MB/s  0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.47.3-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl (357 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading ruff-0.12.11-py3-none-win_amd64.whl (13.0 MB)\n",
      "   ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 5.8/13.0 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.0/13.0 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.0/13.0 MB 24.1 MB/s  0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pytz, pydub, brotli, websockets, tzdata, tomlkit, shellingham, semantic-version, ruff, python-multipart, mdurl, groovy, ffmpy, click, aiofiles, uvicorn, pandas, markdown-it-py, starlette, rich, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\n",
      "   ----------------------------------------  0/25 [pytz]\n",
      "   ----------------------------------------  0/25 [pytz]\n",
      "   ----------------------------------------  0/25 [pytz]\n",
      "   ----------------------------------------  0/25 [pytz]\n",
      "   - --------------------------------------  1/25 [pydub]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ---- -----------------------------------  3/25 [websockets]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   ------ ---------------------------------  4/25 [tzdata]\n",
      "   -------- -------------------------------  5/25 [tomlkit]\n",
      "   -------- -------------------------------  5/25 [tomlkit]\n",
      "   --------- ------------------------------  6/25 [shellingham]\n",
      "   ------------ ---------------------------  8/25 [ruff]\n",
      "   ------------ ---------------------------  8/25 [ruff]\n",
      "   ------------ ---------------------------  8/25 [ruff]\n",
      "   ------------ ---------------------------  8/25 [ruff]\n",
      "   -------------- -------------------------  9/25 [python-multipart]\n",
      "   ---------------- ----------------------- 10/25 [mdurl]\n",
      "   ------------------- -------------------- 12/25 [ffmpy]\n",
      "   -------------------- ------------------- 13/25 [click]\n",
      "   -------------------- ------------------- 13/25 [click]\n",
      "   ---------------------- ----------------- 14/25 [aiofiles]\n",
      "   ------------------------ --------------- 15/25 [uvicorn]\n",
      "   ------------------------ --------------- 15/25 [uvicorn]\n",
      "   ------------------------ --------------- 15/25 [uvicorn]\n",
      "   ------------------------ --------------- 15/25 [uvicorn]\n",
      "   ------------------------ --------------- 15/25 [uvicorn]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   ------------------------- -------------- 16/25 [pandas]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   --------------------------- ------------ 17/25 [markdown-it-py]\n",
      "   ---------------------------- ----------- 18/25 [starlette]\n",
      "   ---------------------------- ----------- 18/25 [starlette]\n",
      "   ---------------------------- ----------- 18/25 [starlette]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   ------------------------------ --------- 19/25 [rich]\n",
      "   -------------------------------- ------- 20/25 [typer]\n",
      "   -------------------------------- ------- 20/25 [typer]\n",
      "   -------------------------------- ------- 20/25 [typer]\n",
      "   ----------------------------------- ---- 22/25 [gradio-client]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   ------------------------------------ --- 23/25 [fastapi]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   -------------------------------------- - 24/25 [gradio]\n",
      "   ---------------------------------------- 25/25 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 click-8.2.1 fastapi-0.116.1 ffmpy-0.6.1 gradio-5.44.1 gradio-client-1.12.1 groovy-0.1.2 markdown-it-py-4.0.0 mdurl-0.1.2 pandas-2.3.2 pydub-0.25.1 python-multipart-0.0.20 pytz-2025.2 rich-14.1.0 ruff-0.12.11 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.3 tomlkit-0.13.3 typer-0.16.1 tzdata-2025.2 uvicorn-0.35.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36dd3a0c-c039-441f-ad09-6dd665ed589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input):\n",
    "    result = orchestrator.run(user_input)[\"result\"]\n",
    "\n",
    "    category = result[\"category\"]\n",
    "    education = result[\"education\"]\n",
    "    recommendations = result[\"recommendations\"]\n",
    "    clarified = result[\"clarified\"]\n",
    "    suicidal = result[\"suicidal_ideation\"]\n",
    "\n",
    "    # Header respons\n",
    "    response = f\"🧠 Hai, terima kasih sudah berbagi.\\n\\n\"\n",
    "\n",
    "    if clarified:\n",
    "        response += \"Kami telah mengklarifikasi input kamu agar lebih jelas.\\n\\n\"\n",
    "\n",
    "    response += f\"**Kategori yang terdeteksi:** {category}\\n\"\n",
    "    response += f\"**Indikasi pikiran menyakiti diri sendiri:** {suicidal}\\n\\n\"\n",
    "\n",
    "    # Edukasi\n",
    "    response += f\"📘 **Penjelasan singkat tentang '{category}':**\\n{education}\\n\\n\"\n",
    "\n",
    "    # Rekomendasi psikolog\n",
    "    if recommendations:\n",
    "        response += \"👥 **Psikolog yang direkomendasikan:**\\n\"\n",
    "        for i, p in enumerate(recommendations, 1):\n",
    "            response += (\n",
    "                f\"{i}. {p['name']} ({p['location']})\\n\"\n",
    "                f\"   ✉️ {p['contact']}\\n\"\n",
    "                f\"   🧠 Keahlian: {', '.join(p['expertise'])}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        response += \"⚠️ Maaf, belum ada rekomendasi psikolog untuk kategori ini.\\n\"\n",
    "\n",
    "    # Penutup\n",
    "    response += \"\\n🙏 Kamu tidak sendiri. Jika kamu merasa butuh bantuan lebih lanjut, silakan hubungi psikolog yang tersedia atau lanjutkan percakapan ini.\"\n",
    "\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9c64e86-4906-4139-a7a3-cb42213ddfcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlangchain\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'langchain' is not defined"
     ]
    }
   ],
   "source": [
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19c382-aeaa-47fd-9f75-edc40fe903a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
